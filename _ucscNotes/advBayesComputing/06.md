---
title: "Stochastic Search Variable Selection (Cont'd)"
date: 2016-01-22
comments: fb
---

###  Problems with SSVN

- Computational issues (large $p$ is a problem)
- Correlation among predictors, say $x\_1,x\_2,x\_3$ are highly correlated, then each of them will be included $1/3$ of the time, instead of including one of the predictors (if they're supposed to be included).
- SSVS not great for more than hundred of predictors
- Not appealing philosophically for a Bayesian


### Shrinkage Priors

- unimportant predictors shrunk to 0; important ones are kept.
- Laplace (Bayesian Lasso)
  - bad shrinkage prior: $f(x) \sim \exp^{-x}$
  - good shrinkage prior: $f(x) \sim a^{-x}$
- research started in 2005
- Polson & Scott (2010, 2012)


### [Global Local Representation](/assets/ams268/bayesReg.pdf)

- global parameter shrinks all coefficients to 0
- local parameter avoids over-shrinking
- Normal Means Problem
$$
\begin{matrix}
  y\_1 & = & \beta\_1 + \epsilon\_1 \\\\
  \vdots & = & \vdots \\\\
  y\_n & = & \beta\_n + \epsilon\_n \\\\
\end{matrix}
$$

***

$$
\begin{matrix}
  \beta\_j | \psi\_j,\tau & \sim & N(0,\psi\_j\tau) \\\\
  \psi\_j & \overset{iid}{\sim} & g \\\\
  \tau & \sim & f \\\\
\end{matrix}
$$

1. $g$ should be heavy tailed
2. $f$ should have sufficient mass around zero

*** 

- Bayesian Lasso (Park and Casella, 2008 (read); Hans 2009). Also a bad prior.
