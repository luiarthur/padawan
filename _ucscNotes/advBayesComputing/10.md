---
title: "Variable selection on BNP"
date: 2016-02-03
comments: cucumber
---

## GP

$$
  \kappa(x\_i,x\_j;\phi) = (x\_i-x\_j)' P (x\_i-x\_j)
$$

where $P$ is a diagonal matrix, and use spike and slab prior on the diagonal
elements of $P$. 

## New Topic

For the model,

$$
\begin{aligned}
  y &= X\beta + \epsilon, \epsilon \sim (N(0,\sigma^2) \\\\
  \beta &\sim \pi
\end{aligned}
$$

say the true model is $y = X\beta^0 + \epsilon$. Then,

$$
  \pi(\beta \in U| y) = \frac{\int\_U~f(y|\beta)~\pi(\beta)~d\beta}{\int~f(y|\beta)~\pi(\beta)~d\beta} = \frac{\int\_U~\frac{f(y|\beta)}{f(y|\beta^0)}~\pi(\beta)~d\beta}{\int~\frac{f(y|\beta)}{f(y|\beta^0)}~\pi(\beta)~d\beta}
$$

Let $U$ be a neighborhood of $\beta$ around $\beta^0$. A model is posterior consistent if $\pi(\beta \in U|y) \rightarrow 1$ as $n\rightarrow\infty$ under $\beta^0$ for any nbd U.

### How do we choose a neighborhood?

- KL nbd around $\beta^0$
    - KL($\beta,\beta^0$) = $\int~f(y|\beta^0)~\log\frac{f(y|\beta^0)}{f(y|\beta)}~dy$
- Hellinger nbd around $\beta^0$
    - H($\beta,\beta^0$) = $\int~\paren{ \sqrt{f(y|\beta^0)} - \sqrt{f(y|\beta)}}^2~dy$
- L2 distance $\norm{\beta-\beta^0}$

- $U = \\{ \beta: \norm{\beta-\beta^0}\_2 \lt \epsilon \\}$ for example.
- L2 norm convergence implies KL, H. KL convergence and H convergence are equivalent.
- If you fix any $\epsilon \gt 0$, $\pi(U\_\epsilon|y) \rightarrow 1$ as $n\rightarrow\infty$ under $\beta^0$

Let $B\_\epsilon = \\{ \beta: \norm{\beta-\beta^0}\_2 \lt \epsilon \\}$. Let us show
$\pi(B\_\epsilon|y) \rightarrow 1$ as $n\rightarrow\infty$.

$$
  \pi(B\_\epsilon| y) = \frac{\int\_{B\_\epsilon}~\frac{f(y|\beta)}{f(y|\beta^0)}~\pi(\beta)~d\beta}{\int\_{\mathbb{R}^p}~\frac{f(y|\beta)}{f(y|\beta^0)}~\pi(\beta)~d\beta}
$$

Let $\\{\Phi\\}^\infty\_{n=1}$ be a sequence of test functions for testing $H\_0:\beta=\beta^0$ vs. $H\_1: \beta \in B\_\epsilon^C$.

$$
  E\_{\beta^0}(\Phi\_n) \le c\_1 \exp\paren{-cn}, ~~~ c, b \gt 0
$$

and $\underset{\beta\in B\_\epsilon^C}{Sup}~E\_\beta\paren{1-\phi\_n} \le b\_1 \exp\paren{-bn}$.

The level of the sequence of tests goes to 0 as $n$ goes to infinity in an exponential rate 
and power function of the sequence of tests goes to 1 as $n$ goes to infinity in an esponential rate.

$$
\begin{aligned}
  \pi(B\_\epsilon| y) &= \frac{\int\_{B\_\epsilon}~\frac{f(y|\beta)}{f(y|\beta^0)}~\pi(\beta)~d\beta}{\int\_{\mathbb{R}^p}~\frac{f(y|\beta)}{f(y|\beta^0)}~\pi(\beta)~d\beta} \\\\
  &= \frac{J\_{B\_\epsilon}}{J} \\\\
  & \le \Phi\_n + \frac{(1-\Phi\_n)J\_{B\_\epsilon}}{J}
\end{aligned}
$$

$$
\begin{aligned}
  P\_{\beta^0} (\Phi\_n \gt \exp\paren{-cn/2}) &\le \frac{E\_{\beta\_0}(\Phi\_n)}{\exp\paren{-cn/2}} \\\\
  &=c\_1 \exp\paren{\frac{-cn}{2}}
\end{aligned}
$$

$\sum\_{n=1}^\infty P\_{\beta^0} (\Phi\_n \gt \exp\paren{-cn/2}) \le \sum\_{n=1}^\infty c\_1 \exp\paren{\frac{-cn}{2}} \lt \infty$ $ \Rightarrow P\_{\beta^0} (\Phi\_n \gt \exp\paren{-cn/2 \text{ infinitely often}}) = 0.$ So, for all but finite number of $n$'s, $\Phi\_n$ goes to 0. (Using Chebychev's then Borel Cantelli)

$\Phi\_n = I\_{\\{ \norm{\hat{\beta\_n}-\beta^0} \gt \epsilon/2 \\}}$, $\hat\beta = (X'X)^{-1}X'y$

***

## Potential Project

- Doing Generalized Pareto on the diagonals of $P$ in a GP (or other shrinkage priors)

***
