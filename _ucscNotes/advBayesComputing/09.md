---
title: "g-prior"
date: "02/01/2016"
comments: fb
---

Let $\phi$ be the precision parameter. The formulations of g-prior is 
$$
  \beta | \phi \sim N(0, \frac{g}{\phi} \paren{X'X}^{-1}), \pi(\phi) \propto 1/\phi
$$
for $n \approx 100-1000, p \approx 16-30$

$\pi(y | M\_\gamma) = \int~like*prior~d\beta d\phi$

For $M\_{null}$, $R\_\gamma^2 = 0, p\_\gamma=0$. So, bayes factor = $\frac{\pi(y|M\_\gamma)}{\pi(y|M\_{null})}= \frac{(1+g)^{(n-1-p\_\gamma)/2}}{[1+g(1-R\_\gamma^2)]^{(n-1)/2}}$

As $g \rightarrow \infty$, BF($M\_\gamma: M\_{null}$) $\rightarrow 0$. This mean that non-informative prior on $\beta$ will help reject the model even if it is correct. (Bartlett Paradox).

As $R\_\gamma^2 \rightarrow 1$, BF $\rightarrow (1+g)^{-p\_\gamma/2}$

Since $M\_\gamma$ approaches to a model with a perfect fit when $R\_\gamma^2 \rightarrow 1$, BF should go to $\infty$. (Information Paradox)

Both paradoxes found in Langer et. al 2008.
