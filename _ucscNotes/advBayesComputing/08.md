---
title: "Compresing Predictors"
date: "01/29/2016"
comments: fb
---

If parameter estimation is not the main goal, but prediction. We don't want to use generalized pareto priors.

### Goal:
Build a preictive model of $y$ on $\underset{p \times 1}{\pmb x}$, $p \approx 50000$.
$\underset{m\times p}{\Phi} \underset{p\times 1}{\pmb x}$, $m \ll p$. $\underset{m\times 1}{\Phi \pmb x}$

### Papers

- Compressed sensing literature (Johnson \& Lindenstrauss, 1984)
- [Bayesian Compressed Regression](http://arxiv.org/abs/1303.0642)


1. k-nearest neighbor clustering
2. Image compression

### Posterior

- $\Sigma=2b\_1 / n$
- $\mu = [\Phi X'X\Phi' + \Sigma\_\beta^{-1}]^{-1}$
- $a\_1=n/2, b\_1=[y'y - y'X\Phi'[\Phi X'X\Phi' + \Sigma\_\beta^{-1}]\Phi X'y]/2$

- $\mu\_{pred} = (\Phi x\_0)'\mu$
- $\sigma^2\_{pred} = 2\frac{b\_1}{n}[ 1 + (\Phi x\_0)' [\Phi X'X\Phi']^{-1} \Phi x\_0]$

Note that the posterior is obtained in closed form, while not in other methods.

### How to choose $m$?

- model averaging
    - create model for each (specified) dimension of $\Phi$
    - $P(\mathcal M\_l | D = \frac{P(D|\mathcal M\_l)P(\mathcal M\_l)}{P(D)}$
    - $P(\mathcal M\_l) = 1/S$, $S$ is the number of models (i.e. number of $m$'s).
    - $P(D|\mathcal M\_l) = \int~ N(y|X\Phi'\beta,\sigma^2I)\pi(\beta|\sigma^2)\pi(\sigma^2) ~d\beta d\sigma^2$
        - $=\frac{1}{|X\Phi'\Sigma\_\beta\Phi X' + I|^{1/2}} \frac{2^{n/2}\Gamma(n/2)}{y'(X\Phi'\Sigma\_beta\Phi X'+I)^{-1}y} (\sqrt{2\pi})^{n/2} $
    - Simulate a new $\Phi$ for each model
    - we don't pick one model, but we use weights for each model and predict with each model

Model has narrower credible intervals and lower MSE, compared to lasso and ridge.


