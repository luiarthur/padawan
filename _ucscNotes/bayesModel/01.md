---
title: Resources
date: 2016-03-29
ams: 207
---

# Resources

- [Course Website](https://ams207-spring16-01.courses.soe.ucsc.edu/)
- [Webcast](https://webcast.ucsc.edu/)
- [Lecture Notes 1](/assets/ams207/notes/notes1.pdf)
- [Lecture Notes 2](/assets/ams207/notes/notes2.pdf)
- [Lecture Notes 3](/assets/ams207/notes/notes3.pdf)
- [Lecture Notes 4](/assets/ams207/notes/notes4.pdf)
- [Lecture Notes 5](/assets/ams207/notes/notes5.pdf)
- [Lecture Notes 6](/assets/ams207/notes/notes6.pdf)
- [Lecture Notes 7](/assets/ams207/notes/notes7.pdf)
- [Lecture Notes 8](/assets/ams207/notes/notes8.pdf)
- [Lecture Notes 9](/assets/ams207/notes/notes9.pdf)
- [Lecture Notes 10 - Efficient Gibbs](/assets/ams207/notes/notes10.pdf)
- [Lecture Notes 11 - EM](/assets/ams207/notes/notes11.pdf)

# Homework
1. Obtain the mean and the variance for the beta-binomial distribution. Show that it tackles   the overdispersion problem. Hint: use the formulas for conditional expectations and variances.
2. Obtain the Laplace approximation for the posterior expection of  logit(mu) and log(tau) in the cancer mortality rate example (data available from the package LearnBayes).
3. Obtain an expression for the posterior variance of the location parameter of a normal likelihood as function of the predictive marginal density. This is an extension of what was shown in class for the posterior mean.
4. Redo the Iris Sepal example.
5. Problems 3.1,3. 2, 3.5; 4.1, 4.2
6. Problems 5.7,5.8,5.10, 5.12
7. Repeat the SAT example with:
    - Direct sampling from the posterior
    - Gibbs sampling from the posterior
    - Abrams and Sans√≥ '98 approximations for the posterior moments
8. Problems 5.14, 5.15
9. Write the Bayes factor, BIC and DIC to compare a model where n observations are assumed to be sampled with a poisson distribution with a gamma prior, to a model where the observations are sampled from a binomial distribution, with a known number of trials and beta prior for the probability of success
10. Consider the SAT example, use the DIC to compare the models with no  pooling, total pooling and partial pooling based on a hierarchical model with unknown variance.
11. Problems 6.2,6.6; 7.4, 7.5
12. Problems 8.11, 8.14
13. For each of the examples considered in class regarding the censored and truncated weights data develop an approach based on MCMC with auxiliary variables and write the full conditionals.
14. Consider the following data regarding the heights in inches of male students at a college. First interval: less than 66, counts 14; second interval 66 to 68, counts 30; third interval 68 to 70, counts 49; fourth interval 70 to 72, counts 70; fifth interval 72 to 74, counts 33; sixth interval greater than 74, counts 15. Assume that the height of students is normally distributed, and assume a non-informative distribution for the parameters of the normal.
    - Use Metroplis Hastings to estimate the parameters of the normal using a multinomial likelihood.
    - Introduce latent variables and use Gibbs sampling to do the estimation. Compare.

***

## Terminology

Unidentifiability
: Parameters are *unidentifiable* if they cannot be estimated uniquely due to different sets of parameter values leading to the same evaluation of the likelihood. For example, in

$$
  y_i = N(ab,\sigma^2)
$$

$(a,b)$ is unidentifiable because for a particular value of $(a=a',b=b')$, $(a=\frac{a'}{c},b=b'c)$, for some constant $c$, would yield the same likelihood.

